{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[11835 11835]\n",
      "Epoch 1/25\n",
      "11835/11835 [==============================] - 0s 21us/step - loss: 0.3281 - acc: 0.5190\n",
      "Epoch 2/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.3203 - acc: 0.5190\n",
      "Epoch 3/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.3127 - acc: 0.5190\n",
      "Epoch 4/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.3055 - acc: 0.5190\n",
      "Epoch 5/25\n",
      "11835/11835 [==============================] - 0s 13us/step - loss: 0.2987 - acc: 0.5190\n",
      "Epoch 6/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.2924 - acc: 0.5190\n",
      "Epoch 7/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.2866 - acc: 0.5190\n",
      "Epoch 8/25\n",
      "11835/11835 [==============================] - 0s 14us/step - loss: 0.2813 - acc: 0.5190\n",
      "Epoch 9/25\n",
      "11835/11835 [==============================] - 0s 13us/step - loss: 0.2766 - acc: 0.5190\n",
      "Epoch 10/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.2724 - acc: 0.5190\n",
      "Epoch 11/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.2688 - acc: 0.5190\n",
      "Epoch 12/25\n",
      "11835/11835 [==============================] - 0s 13us/step - loss: 0.2656 - acc: 0.5190\n",
      "Epoch 13/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.2629 - acc: 0.5190\n",
      "Epoch 14/25\n",
      "11835/11835 [==============================] - 0s 13us/step - loss: 0.2606 - acc: 0.5190\n",
      "Epoch 15/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.2587 - acc: 0.5190\n",
      "Epoch 16/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.2570 - acc: 0.5190\n",
      "Epoch 17/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.2557 - acc: 0.5190\n",
      "Epoch 18/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.2546 - acc: 0.5190\n",
      "Epoch 19/25\n",
      "11835/11835 [==============================] - 0s 12us/step - loss: 0.2537 - acc: 0.5190\n",
      "Epoch 20/25\n",
      "11835/11835 [==============================] - 0s 13us/step - loss: 0.2529 - acc: 0.5190\n",
      "Epoch 21/25\n",
      "11835/11835 [==============================] - 0s 14us/step - loss: 0.2523 - acc: 0.5190\n",
      "Epoch 22/25\n",
      "11835/11835 [==============================] - 0s 15us/step - loss: 0.2518 - acc: 0.5190\n",
      "Epoch 23/25\n",
      "11835/11835 [==============================] - 0s 16us/step - loss: 0.2514 - acc: 0.5190\n",
      "Epoch 24/25\n",
      "11835/11835 [==============================] - 0s 15us/step - loss: 0.2510 - acc: 0.5190\n",
      "Epoch 25/25\n",
      "11835/11835 [==============================] - 0s 17us/step - loss: 0.2508 - acc: 0.5190\n",
      "[[0.5575988  0.50373167]\n",
      " [0.5575986  0.50373185]\n",
      " [0.5575989  0.5037315 ]\n",
      " ...\n",
      " [0.5575991  0.50373155]\n",
      " [0.55759895 0.5037316 ]\n",
      " [0.55760175 0.5037296 ]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_135 (Dense)            (None, 100)               7800      \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 18,102\n",
      "Trainable params: 18,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------\n",
    "# Lab 2 - GTI770\n",
    "#------------------------------------------\n",
    "\n",
    "\n",
    "# Import des libraries necessaires\n",
    "from skimage import io, novice\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#For Keras MLP\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import numpy as np\n",
    "import operator \n",
    "\n",
    "#https://docs.python.org/2/library/csv.html\n",
    "import csv\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "# -------------------------------------MAIN PROGRAM------------------------------------------------------\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#------------------Section Définition de fonctions-----------\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "# On a besoin de cette fonction car la conversion de nparray laisse toutes les données en np_str et on veux float\n",
    "def convertStringsToFloats(array):\n",
    "    convertedArray = []\n",
    "    for element in array:\n",
    "        convertedArray.append(float(element))\n",
    "    return convertedArray\n",
    "\n",
    "#Séparation des données en test/train\n",
    "def floatMapTrainValidTest(data, labels):\n",
    "\n",
    "    trainFeatures, validFeatures, trainLabels, validLabels = train_test_split(data, labels, test_size=0.30)\n",
    "    validFeatures, testFeatures, validLabels, testLabels = train_test_split(validFeatures, validLabels, test_size=0.33)\n",
    "    \n",
    "    floatDataMap = {\"trainFeatures\" : [], \n",
    "                   \"trainLabels\" : [], \n",
    "                   \"validFeatures\" : [],\n",
    "                   \"validLabels\" : [],\n",
    "                   \"testFeatures\" : [], \n",
    "                   \"testLabels\" : []\n",
    "                   }\n",
    "    \n",
    "    for row in trainFeatures:\n",
    "        floatDataMap[\"trainFeatures\"].append(convertStringsToFloats(row))\n",
    "        \n",
    "    for row in validFeatures:\n",
    "        floatDataMap[\"validFeatures\"].append(convertStringsToFloats(row))\n",
    "        \n",
    "    for row in testFeatures:\n",
    "        floatDataMap[\"testFeatures\"].append(convertStringsToFloats(row))\n",
    "        \n",
    "    for row in trainLabels:\n",
    "        floatDataMap[\"trainLabels\"].append(row)\n",
    "        \n",
    "    for row in validLabels:\n",
    "        floatDataMap[\"validLabels\"].append(row)\n",
    "        \n",
    "    for row in testLabels:\n",
    "        floatDataMap[\"testLabels\"].append(row)\n",
    "        \n",
    "    return floatDataMap\n",
    "\n",
    "\n",
    "#Conversion des labels de validation de format bizarres\n",
    "def arrangeLabels(labels):\n",
    "    newLabels = []\n",
    "    for label in labels:\n",
    "        newLabels.append(label[0])\n",
    "    return newLabels\n",
    "\n",
    "#Printing of graphs\n",
    "def printGraph(x, y, title):\n",
    "\n",
    "    plt.plot(x, y)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()\n",
    "\n",
    "     \n",
    "def crossValidation(trainLabels, trainFeatures, validationLabels, validationFeatures, testLabels, testFeatures, case):\n",
    "    \n",
    "    print()\n",
    "    print(case)\n",
    "    \n",
    "    dataFeatures = trainFeatures + validationFeatures + testFeatures\n",
    "    dataLabels = trainLabels + validationLabels + testLabels\n",
    "    \n",
    "    accuracyScoreList = []\n",
    "    f1ScoreList = []\n",
    "    \n",
    "    kf = KFold(n_splits=10)\n",
    "    for train_index, test_index in kf.split(dataFeatures):\n",
    "        \n",
    "        \n",
    "        newTrainFeatures = []\n",
    "        newTrainLabels = []\n",
    "        newTestFeatures = []\n",
    "        newTestLabels = []\n",
    "        \n",
    "        \n",
    "        for index in train_index:\n",
    "            newTrainFeatures.append(dataFeatures[index])\n",
    "            newTrainLabels.append(dataLabels[index])\n",
    "            \n",
    "        for index in test_index:\n",
    "            newTestFeatures.append(dataFeatures[index])\n",
    "            newTestLabels.append(dataLabels[index])\n",
    "        \n",
    "        #Add iteratively testing model function logic in here\n",
    "    \n",
    "    print(\"Cross-Val Accuracy: \")   \n",
    "    print(np.mean(accuracyScoreList))\n",
    "    print(\"Cross-Val F1: \")\n",
    "    print(np.mean(f1ScoreList))\n",
    "        \n",
    "# À modifier pour votre environmement - Galaxy\n",
    "galaxyFeatureVectorFolderLocation = 'C:/Users/turco/gti770/'\n",
    "\n",
    "# Lecture de fichier -> Utiliser après l'extraction des données du TP01\n",
    "# Ici on a besoin du CSV \n",
    "galaxyVectorFid = open(galaxyFeatureVectorFolderLocation + 'features.csv', 'r') # option r veut dire read\n",
    "galaxyVectorTxt = galaxyVectorFid.readlines() # Cette ligne permet de lire tout le fichier \n",
    "galaxyVectorFid.close() \n",
    "\n",
    "galaxyFeatureVector=[]\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#------------------Section Extraction de primitives (CSV) (Galaxie)-----------\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "for line in galaxyVectorTxt:\n",
    "    columns = line[:-1]\n",
    "    columns = columns.split(',')\n",
    "    galaxyFeatureVector.append(columns)\n",
    "    \n",
    "    \n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#------------------Section Manipulation---------------------\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "#Manipulations des données pour la séparation en apprentissage, validation et test\n",
    "\n",
    "# Explication de 'splicing': \n",
    "# iris.data[:, :3] veut dire qu'on utilise la totalite des \"rows\" et seulement 3 colonnes [:, 3]\n",
    "# pour utiliser seulement 3 \"rows\" et la totalite des colonnes on utilise [:3, :]\n",
    "galaxyFeatureVector = np.array(galaxyFeatureVector)\n",
    "\n",
    "spiralFeatures = []\n",
    "spiralLabels = []\n",
    "\n",
    "smoothFeatures = []\n",
    "smoothLabels = []\n",
    "\n",
    "#Séparation par étiquettes\n",
    "\n",
    "#Séparation des galaxies\n",
    "for row in galaxyFeatureVector:\n",
    "    if (row[0] == \"spiral\"):\n",
    "        spiralFeatures.append(row[1:])\n",
    "        spiralLabels.append(0)\n",
    "    else:\n",
    "        smoothFeatures.append(row[1:])\n",
    "        smoothLabels.append(1)\n",
    "        \n",
    "\n",
    "#Séparation de train/valid/test\n",
    "\n",
    "smoothData = {\"trainFeatures\" : [], \n",
    "           \"trainLabels\" : [], \n",
    "           \"validFeatures\" : [],\n",
    "           \"validLabels\" : [],\n",
    "           \"testFeatures\" : [], \n",
    "           \"testLabels\" : []\n",
    "           }\n",
    "\n",
    "\n",
    "spiralData = {\"trainFeatures\" : [], \n",
    "           \"trainLabels\" : [], \n",
    "           \"validFeatures\" : [],\n",
    "           \"validLabels\" : [],\n",
    "           \"testFeatures\" : [], \n",
    "           \"testLabels\" : []\n",
    "           }\n",
    "\n",
    "#Séparation galaxies avec one hot encoding pour les étiquettes!\n",
    "smoothData = floatMapTrainValidTest(smoothFeatures, smoothLabels)\n",
    "spiralData = floatMapTrainValidTest(spiralFeatures, spiralLabels)\n",
    "\n",
    "trainFeatures = normalize(np.asarray(smoothData[\"trainFeatures\"] + spiralData[\"trainFeatures\"]))\n",
    "trainLabels = to_categorical(smoothData[\"trainLabels\"] + spiralData[\"trainLabels\"])\n",
    "\n",
    "testFeatures = normalize(np.asarray(smoothData[\"testFeatures\"] + spiralData[\"testFeatures\"]))\n",
    "testLabels = to_categorical(smoothData[\"testLabels\"] + spiralData[\"testLabels\"])\n",
    "\n",
    "validationFeatures = normalize(np.asarray(smoothData[\"validFeatures\"] + spiralData[\"validFeatures\"]))\n",
    "validationLabels = to_categorical(smoothData[\"validLabels\"] + spiralData[\"validLabels\"])\n",
    "\n",
    "\n",
    "# unique_elements, counts_elements = np.unique(trainLabels, return_counts=True)\n",
    "\n",
    "# print(unique_elements)\n",
    "# print(counts_elements)\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#------------------Section Réseau de neuronnes----------------\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='sigmoid', input_dim=77))\n",
    "model.add(Dense(units=100, activation='sigmoid'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "\n",
    "#Learning rate en paramètre içi avec l'optimization SGD\n",
    "sgd = keras.optimizers.SGD(lr=0.0005)\n",
    "\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['accuracy'])\n",
    "\n",
    "#Utilise: tensorboard --logdir=./logs/keras_nn --host=127.0.0.1 Appèle cette fonction \n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir='./logs/keras_nn')\n",
    "\n",
    "model.fit(trainFeatures, trainLabels, epochs=25, batch_size=100, callbacks=[tb_callback])\n",
    "\n",
    "print(model.predict(testFeatures))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#---------------------------Section SVM-----------------------\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "# -------------------------------------END PROGRAM-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
